{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script para web scraping Strava\n",
    "\n",
    ">O script se baseia no uso de 2 bibliotecas, a ***Selenium*** e a ***Beatiful Soup***. Sendo a primeira responsável pela navegação nas páginas, isto é, desde login até movimentação da página, acessando hyperlinks e botões em java Script. Já a segunda é responsável pela cópia do código fonte, a partir da configuração de paramêtros, e retorno das chamadas. Em grandes linhas, buscamos a tabela onde os dados estão, e posteriormente extraimos a informação necessária.\n",
    "\n",
    "*Necessário: Instalação das bibliotecas Selenium e BeautifulSoup, e também do webdriver do chrome para que o navegador seja acessado remotamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Inicialização do navegador remotamente, e carregamento da página inicial do strava. O tempo de 5s é para o carregamento inicial.\n",
    "2. Solicitação de login e senha. \n",
    "3. O campo usuário e senha é localizado na página através da biblioteca Selenium, e posteriormente é preenchido e clicado.\n",
    "4. Substituir o campo ***url_evento*** pela url do evento do strava, ou seja, a corrida.\n",
    "\n",
    "## Alterar campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email=input(prompt=\"Digite seu email strava:\")\n",
    "senha=input(prompt=\"Digite sua senha strava:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterar campos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.strava.com/login')\n",
    "time.sleep(5)\n",
    "url_evento = 'https://www.strava.com/segments/19286937'\n",
    "export = \"CHICAGO-001.csv\"\n",
    "ultima_pagina = 850\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A identificação dos campos ***usuário*** e ***senha*** é feito através da funcionalidade \"inspeção do código fonte\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = driver.find_element_by_id(\"email\")\n",
    "password = driver.find_element_by_id(\"password\")\n",
    "\n",
    "\n",
    "username.send_keys(email)\n",
    "password.send_keys(senha)\n",
    "driver.find_element_by_id(\"login-button\").click() #encontrar o elemento botão\n",
    "time.sleep(2)\n",
    "\n",
    "driver.get(url_evento)\n",
    "time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> São utilizados 5 listas para o armazenamento das informações, sendo elas:\n",
    "* results (n x 7) - ['classificacao','nome', 'ano','pace', 'fc', 'vam','tempo_liquido'] sem tratamento\n",
    "* result_faixa_etaria (n x 1) - faixas etárias\n",
    "* result_sexo (n x 1) - masculino / feminino\n",
    "* data (n x 1) - ['classificacao','nome', 'ano','pace', 'fc', 'vam','tempo_liquido'] sem valores nulos\n",
    "* link_atividades (n x 1) - link para ser direcionado aos detalhes do evento que o  atleta tenha participado\n",
    "\n",
    "Foram criados ainda 3 dicionários, onde o índice é a posição para localização (xpath) do item:\n",
    "\n",
    "Ex: ``element=driver.find_element_by_xpath('//*[@id=\"segment-results\"]/div[2]/table/tbody/tr/td[4]/div/ul/li['+str(se)+']/a')``\n",
    "\n",
    "O valor ***se*** e ***fe*** são iterados no laço ***for*** para os indices do sexo e faixa etária.\n",
    "Futuramente o dicionário de ***classe_peso*** poderá ser utilizado, nesse momento os dados não foram captados devido a uma independência dos filtros de **faixa_etaria e classe_peso**. Poderá ser implementando um script complementar para o preenchimento desse campo e **merge** com os demais campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "result_faixa_etaria = []\n",
    "result_sexo=[]\n",
    "data = []\n",
    "link_atividades = []\n",
    "\n",
    "faixa_etaria={'2':'19 e abaixo','3':'20 a 24','4':'25 a 34','5':'35 a 44','6':'45 a 54','7':'55 a 64','8':'65 a 69',\n",
    "              '9':'70 a 74','10':'75+'}\n",
    "sexo={'2':'Homens','3':'Mulheres'}\n",
    "classe_peso={'54 kg e abaixo','55 a 64 kg', '75 a 84 kg','85 a 95 kg','95 kg a 104 kg','105 kg a 114 kg','115 kg e acima'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core\n",
    ">O core está separado em 4 laços **for**, sendo o primeiro para seleção do filtro de **homens/mulheres**, o segundo para seleção do filtro de **faixa etária**, o terceiro para navegação entre as **paginas**, e o quarto para extração dos **dados**.\n",
    "\n",
    "1. O script clica no sexo masculino\n",
    "2. Seleciona a primeira faixa etária (19 e abaixo)\n",
    "3. Mantém selecionado o sexo masculino\n",
    "4. Armazena os dados da primeira página na variável **rows**\n",
    "5. Utiliza-se um laço **for** para extração dos dados e preenchimento das listas (citadas anteriormente)\n",
    "6. Clica-se na próxima página - caso não tenha uma próxima, sai do atual laço de extração.\n",
    "7. Seleciona-se a próxima faixa etária, e retorno para o passo 3\n",
    "\n",
    "Durante os laços a **url_evento** é carregada algumas vezes para organizar a navegação do chrome.\n",
    "\n",
    ">Após a extração dos dados cria-se 4 dataframes, e em seguida suas colunas são concatenadas num único dataframe, e é gerado um arquivo csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for se in range(2,4):\n",
    "    element=driver.find_element_by_xpath('//*[@id=\"segment-results\"]/div[2]/table/tbody/tr/td[4]/div/ul/li['+str(se)+']/a')\n",
    "    driver.execute_script(\"arguments[0].click();\", element) #clique do botão em javascript\n",
    "    time.sleep(1)\n",
    "    \n",
    "    for fe in range(2,11):\n",
    "        \n",
    "        try:\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"premium-enhanced\"]/ul/ul[1]/li['+str(fe)+']/a')\n",
    "            driver.execute_script(\"arguments[0].click();\", element) #clique do botão em javascript\n",
    "            time.sleep(2)\n",
    "\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"segment-results\"]/div[2]/table/tbody/tr/td[4]/div/ul/li['+str(se)+']/a')\n",
    "            driver.execute_script(\"arguments[0].click();\", element) #clique do botão em javascript\n",
    "            time.sleep(2)\n",
    "\n",
    "            for page_number in range(0,ultima_pagina):\n",
    "                dados = driver.find_element_by_id(\"segment-leaderboard\")\n",
    "                html=dados.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(html, \"html.parser\") #estruturação do código na variável soup\n",
    "                table = soup.find(\"table\", attrs={\"class\": \"table table-striped table-padded table-leaderboard\"}) #identificação da tabela\n",
    "                rows = table.findAll(\"tr\") # \"tr\" é o local no código onde estão as informações na tabela (linha)\n",
    "                print('Página {p} de {u} do sexo {s} da faixa etária {f}'.format(p=page_number,u=ultima_pagina,s=se,f=fe))\n",
    "\n",
    "                for row in rows:\n",
    "                    a = [t.text.strip() for t in row.findAll(\"td\")][0:] #\"td\" é um nível abaixo de \"tr\" (coluna para cada linha)\n",
    "                    b = [c['href'] for c in row.find_all('a', href=True) if c.text] #identificação dos hyperlinks para a atividade do atleta\n",
    "                    if len(a) > 0 and a != [''] and a !=['',''] and a != ['', '', ''] :\n",
    "                        results.append(a)\n",
    "                        result_faixa_etaria.append(faixa_etaria[str(fe)])\n",
    "                        result_sexo.append(sexo[str(se)])\n",
    "                        try:\n",
    "                            link_atividades.append('https://strava.com' + b[1])\n",
    "                        except Exception:\n",
    "                            link_atividades.append(np.nan)\n",
    "\n",
    "\n",
    "                try:\n",
    "                    prox_pag=driver.find_element_by_link_text(\"→\").click()\n",
    "\n",
    "\n",
    "                except Exception:\n",
    "                    driver.get(url_evento)\n",
    "                    break\n",
    "                time.sleep(2)\n",
    "\n",
    "            driver.get(url_evento)\n",
    "        except:\n",
    "            next\n",
    "data = []\n",
    "for i, result in enumerate(results):\n",
    "    data.append(results[i])\n",
    "\n",
    "df_faixa_etaria=pd.DataFrame(result_faixa_etaria,columns=['faixa_etaria'])\n",
    "df_sexo=pd.DataFrame(result_sexo,columns=['sexo'])\n",
    "df_link_atividades=pd.DataFrame(link_atividades,columns=['segmento'])\n",
    "df_link_atleta = pd.DataFrame(link_atleta,columns=['atleta'])\n",
    "\n",
    "\n",
    "columns = ['classificacao','nome', 'ano','pace', 'fc','tempo_liquido']\n",
    "df=pd.DataFrame(data,columns=columns)\n",
    "\n",
    "df=pd.concat([df,df_faixa_etaria,df_sexo,df_link_atividades,df_link_atleta],axis=1)\n",
    "\n",
    "df.drop(df[df['classificacao']=='Nenhum resultado encontrado'].index,inplace=True) #apagar as linhas que mostram como \"nenhum arquivo encontrado\", isso ocorre devido a faixas_etárias sem dados.\n",
    "\n",
    "df.to_csv(exportbase,index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
